# Breweries Data Pipeline (Dockerized)

This project demonstrates a data pipeline that consumes data from the Open Brewery DB API, transforms it, and persists it into a data lake following the medallion architecture: Bronze → Silver → Gold, fully containerized with Docker.

---

## **Project Objective**

- Fetch brewery data from the Open Brewery DB API
- Persist raw data in Bronze Layer
- Transform and store data in Silver Layer as Parquet, partitioned by state & city
- Aggregate data in Gold Layer for analytics: count of breweries by type and location
- Include automated tests for each layer

---

## **Project Structure**

BreweriesCase/

├─ data/

│  ├─ bronze/   # Raw JSON from API

│  ├─ silver/   # Parquet partitioned by state/city

│  └─ gold/     # Aggregated Parquet

├─ src/

│  ├─ api/

│  │  └─ breweries_api.py        # Bronze Layer extraction

│  └─ pipeline/

│     ├─ luigi_pipeline.py

│  └─ transformations/

│     ├─ bronze_to_silver.py     # Bronze → Silver

│     └─ silver_to_gold.py       # Silver → Gold

├─ tests/

│  ├─ 1 test_bronze_layer.py     # Bronze Layer tests

│  ├─ 2 test_silver_layer.py     # Silver Layer tests

│  └─ 3 test_gold_layer.py       # Gold Layer tests

├─ Dockerfile

├─ docker-compose.yml

├─ README.md

└─ requirements.txt


## **Prerequisites**

- Docker
- Docker Compose

## **Pipeline Execution (Docker)**

1. Run the entire pipeline (Bronze → Silver → Gold)
docker-compose up --build pipeline

- All data will be persisted in ./data on the host machine:
- data/bronze/ → raw JSON
- data/silver/ → Parquet partitioned by state/city
- data/gold/ → aggregated Parquet

2. Run individual layers

- Bronze (API extraction):
docker-compose up --build bronze

- Silver (Bronze → Silver transformation):
docker-compose up --build silver

- Gold (Silver → Gold aggregation):
docker-compose up --build gold

3. Run automated tests
docker-compose up --build tests

tests/2 test_bronze_layer.py → checks Bronze Layer creation
tests/2 test_silver_layer.py → checks Silver Layer creation
tests/3 test_gold_layer.py → checks Gold Layer aggregation

4. Interactive container for debugging
docker-compose run pipeline bash

All services have tty: true, so you can explore the container environment, inspect data, or manually run any script.

## **Layer Details**

- Bronze Layer

Fetch raw data from Open Brewery DB API (src/api/breweries_api.py)
Output: data/bronze/breweries_raw.json

- Silver Layer
Transform raw JSON into Parquet, partitioned by state & city (src/transformations/bronze_to_silver.py)
Output: data/silver/state=.../city=.../data.parquet

Transformations Applied:
Filter relevant columns for analytics
Handle missing values: strings → empty "", numeric → NaN
Partitioned by state and city for optimized querying

- Gold Layer
Aggregate Silver Layer to count breweries by brewery_type, state, and city (src/transformations/silver_to_gold.py)
Output: data/gold/breweries_aggregated.parquet

Aggregation Applied:
brewery_count = number of breweries per brewery_type per location
Columnar storage for analytics

## **Notes**

- All scripts are modular (src/api for extraction, src/transformations for ETL)
- Data layers are separated in data/bronze, data/silver, data/gold
- Docker ensures consistent environment across machines
- All data generated by the pipeline is persisted to the host in ./data