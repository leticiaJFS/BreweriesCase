# Breweries Data Pipeline (Dockerized)

This project demonstrates a data pipeline that consumes data from the Open Brewery DB API, transforms it, and persists it into a data lake following the medallion architecture: Bronze → Silver → Gold, fully containerized with Docker.

---

## **Project Objective**

- Fetch brewery data from the Open Brewery DB API
- Persist raw data in Bronze Layer
- Transform and store data in Silver Layer as Parquet, partitioned by state & city
- Aggregate data in Gold Layer for analytics: count of breweries by type and location
- Include automated tests for each layer

---

## **Project Structure**

BreweriesCase/

├─ data/

│  ├─ bronze/   # Raw JSON from API

│  ├─ silver/   # Parquet partitioned by state/city

│  └─ gold/     # Aggregated Parquet

├─ src/

│  ├─ api/

│  │  └─ breweries_api.py        # Bronze Layer extraction

│  └─ pipeline/

│     ├─ luigi_pipeline.py

│  └─ transformations/

│     ├─ bronze_to_silver.py     # Bronze → Silver

│     └─ silver_to_gold.py       # Silver → Gold

│  └─ pyspark/                   # PySpark equivalents

│     ├─ bronze_to_silver_spark.py     # PySpark version (example)

│     └─ silver_to_gold_spark.py

├─ tests/

│  ├─ 1 test_bronze_layer.py     # Bronze Layer tests

│  ├─ 2 test_silver_layer.py     # Silver Layer tests

│  └─ 3 test_gold_layer.py       # Gold Layer tests

├─ Dockerfile

├─ docker-compose.yml

├─ README.md

└─ requirements.txt


## **Prerequisites**

- Docker
- Docker Compose

## **Pipeline Execution (Docker)**

1. Run the entire pipeline (Bronze → Silver → Gold)
docker-compose up --build pipeline

- All data will be persisted in ./data on the host machine:
- data/bronze/ → raw JSON
- data/silver/ → Parquet partitioned by state/city
- data/gold/ → aggregated Parquet

2. Run individual layers

- Bronze (API extraction): 

docker-compose up --build bronze

- Silver (Bronze → Silver transformation): 

docker-compose up --build silver

- Gold (Silver → Gold aggregation): 

docker-compose up --build gold

3. Run automated tests
docker-compose up --build tests

tests/1 test_bronze_layer.py → checks Bronze Layer creation

tests/2 test_silver_layer.py → checks Silver Layer creation

tests/3 test_gold_layer.py → checks Gold Layer aggregation

4. Interactive container for debugging

docker-compose run pipeline bash

All services have tty: true, so you can explore the container environment, inspect data, or manually run any script.

## **PySpark Equivalent Scripts (Optional)**

This project includes PySpark versions of the transformation scripts to demonstrate knowledge of PySpark, following the same medallion architecture.

Location: src/pyspark/

Scripts:

bronze_to_silver.py → PySpark equivalent of Bronze → Silver transformation

silver_to_gold.py → PySpark equivalent of Silver → Gold aggregation

These scripts are not runnable on Windows without a proper Spark environment. They are provided for demonstration purposes to show familiarity with the PySpark API.

## **Layer Details**

- Bronze Layer

Fetch raw data from Open Brewery DB API (src/api/breweries_api.py)
Output: data/bronze/breweries_raw.json

- Silver Layer
Transform raw JSON into Parquet, partitioned by state & city (src/transformations/bronze_to_silver.py)
Output: data/silver/state=.../city=.../data.parquet

Transformations Applied:
- Filter relevant columns for analytics
- Handle missing values: strings → empty "", numeric → NaN
- Partitioned by state and city for optimized querying

- Gold Layer
Aggregate Silver Layer to count breweries by brewery_type, state, and city (src/transformations/silver_to_gold.py)
Output: data/gold/breweries_aggregated.parquet

Aggregation Applied:
- brewery_count = number of breweries per brewery_type per location
- Columnar storage for analytics

## **Notes**

- All scripts are modular (src/api for extraction, src/transformations for ETL)
- Data layers are separated in data/bronze, data/silver, data/gold
- Docker ensures consistent environment across machines
- All data generated by the pipeline is persisted to the host in ./data

## **Monitoring & Alerting**
The monitoring and alerting process aims to ensure reliability, traceability, and data quality across all pipeline stages — from API extraction to the Gold Layer generation.

1. Pipeline Execution Monitoring (Luigi Scheduler)
The Luigi Scheduler UI provides real-time visibility into task execution status:

- Success: task completed successfully.

- Pending/Running: task in progress or waiting for dependencies.

- Failed: task failed, with detailed logs available for debugging.

The Luigi web interface can be accessed at: http://localhost:8082

Execution logs are stored locally under /app/logs/.

2. Failure Alerting

Automatic alerts can be configured to detect and report task failures through:

Email or Slack notifications using a Luigi event handler or a custom notification task.

Webhook / API integrations with tools such as Grafana OnCall, PagerDuty, or Microsoft Teams.

3. Data Quality Monitoring

Before writing to the Gold Layer, the pipeline includes data validation checks to ensure data integrity:

Detection of null values in key columns.

Duplicate row checks.

Type validation (e.g., float, string, date).

Consistency validation across datasets (e.g., totals, date ranges).


4. Advanced Observability 

For production environments, logs and metrics can be integrated with external observability tools:

Prometheus + Grafana → to track task duration, latency, and error rates.

Elastic Stack (ELK) → to centralize and analyze pipeline logs.